{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import (\n",
    "    Input, Embedding, Flatten, Dot, Add, Dense, Dropout, Concatenate\n",
    ")\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sample import get_saved_samples\n",
    "from tensorflow.keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming 'getSavedSamples()' is defined elsewhere and available\n",
    "users, ratings, books = get_saved_samples()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "nUsers = ratings['User-ID'].nunique()\n",
    "nBooks = ratings['ISBN'].nunique()\n",
    "\n",
    "# Embedding size and regularization parameter\n",
    "embeddingSize = 15\n",
    "regularization = 1e-6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# User Embeddings\n",
    "userInput = Input(shape=(1,))\n",
    "userEmbedding = Embedding(nUsers, embeddingSize, embeddings_regularizer=l2(regularization), input_length=1)(userInput)\n",
    "userVector = Flatten()(userEmbedding)\n",
    "userBias = Embedding(nUsers, 1, input_length=1)(userInput)\n",
    "userBias = Flatten()(userBias)\n",
    "\n",
    "# Book Embeddings\n",
    "bookInput = Input(shape=(1,))\n",
    "bookEmbedding = Embedding(nBooks, embeddingSize, embeddings_regularizer=l2(regularization), input_length=1)(bookInput)\n",
    "bookVector = Flatten()(bookEmbedding)\n",
    "bookBias = Embedding(nBooks, 1, input_length=1)(bookInput)\n",
    "bookBias = Flatten()(bookBias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate user and book vectors\n",
    "concatenated = Concatenate()([userVector, bookVector])\n",
    "\n",
    "# Increase the dropout rate\n",
    "dropoutRate = 0.5\n",
    "dense1 = Dense(64, activation='relu')(concatenated)\n",
    "dropout1 = Dropout(dropoutRate)(dense1)\n",
    "dense2 = Dense(32, activation='relu')(dropout1)\n",
    "dropout2 = Dropout(dropoutRate)(dense2)\n",
    "output = Dense(1)(dropout2)\n",
    "\n",
    "# Add biases\n",
    "output = Add()([output, userBias, bookBias])\n",
    "\n",
    "# Construct the model\n",
    "model = Model(inputs=[userInput, bookInput], outputs=output)\n",
    "model.compile(optimizer='adam', loss='mean_squared_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2695/2695 [==============================] - 46s 17ms/step - loss: 12.9034 - val_loss: 15.6324\n",
      "Epoch 2/10\n",
      "2695/2695 [==============================] - 43s 16ms/step - loss: 9.2620 - val_loss: 17.2307\n",
      "Epoch 3/10\n",
      "2695/2695 [==============================] - 42s 16ms/step - loss: 6.4942 - val_loss: 19.1634\n",
      "Epoch 4/10\n",
      "2695/2695 [==============================] - 40s 15ms/step - loss: 5.3967 - val_loss: 19.6947\n",
      "Epoch 5/10\n",
      "2695/2695 [==============================] - 43s 16ms/step - loss: 4.8372 - val_loss: 19.9897\n",
      "Epoch 6/10\n",
      "2695/2695 [==============================] - 43s 16ms/step - loss: 4.4637 - val_loss: 18.4111\n",
      "Epoch 7/10\n",
      "2695/2695 [==============================] - 46s 17ms/step - loss: 4.1663 - val_loss: 18.4765\n",
      "Epoch 8/10\n",
      "2695/2695 [==============================] - 45s 17ms/step - loss: 3.9237 - val_loss: 18.0707\n",
      "Epoch 9/10\n",
      "2695/2695 [==============================] - 42s 16ms/step - loss: 3.7058 - val_loss: 18.0232\n",
      "Epoch 10/10\n",
      "2695/2695 [==============================] - 45s 17ms/step - loss: 3.5897 - val_loss: 17.6854\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x1d897147410>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# %%\n",
    "# Preparing the dataset for training\n",
    "userIdEncoder = LabelEncoder()\n",
    "userIds = userIdEncoder.fit_transform(ratings['User-ID'].astype(str))\n",
    "\n",
    "bookIdEncoder = LabelEncoder()\n",
    "bookIds = bookIdEncoder.fit_transform(ratings['ISBN'].astype(str))\n",
    "ratings = ratings['Book-Rating'].values\n",
    "\n",
    "# Early stopping\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "\n",
    "# Train the model\n",
    "model.fit([userIds, bookIds], ratings, epochs=10, validation_split=0.2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
