{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import (\n",
    "    Input, Embedding, Flatten, Dot, Add, Dense, Dropout, Concatenate\n",
    ")\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sample import get_saved_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming 'getSavedSamples()' is defined elsewhere and available\n",
    "users, ratings, books = get_saved_samples()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "nUsers = ratings['User-ID'].nunique()\n",
    "nBooks = ratings['ISBN'].nunique()\n",
    "\n",
    "# Embedding size and regularization parameter\n",
    "embeddingSize = 15\n",
    "regularization = 1e-6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# User Embeddings\n",
    "userInput = Input(shape=(1,))\n",
    "userEmbedding = Embedding(nUsers, embeddingSize, embeddings_regularizer=l2(regularization), input_length=1)(userInput)\n",
    "userVector = Flatten()(userEmbedding)\n",
    "userBias = Embedding(nUsers, 1, input_length=1)(userInput)\n",
    "userBias = Flatten()(userBias)\n",
    "\n",
    "# Book Embeddings\n",
    "bookInput = Input(shape=(1,))\n",
    "bookEmbedding = Embedding(nBooks, embeddingSize, embeddings_regularizer=l2(regularization), input_length=1)(bookInput)\n",
    "bookVector = Flatten()(bookEmbedding)\n",
    "bookBias = Embedding(nBooks, 1, input_length=1)(bookInput)\n",
    "bookBias = Flatten()(bookBias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate user and book vectors\n",
    "concatenated = Concatenate()([userVector, bookVector])\n",
    "\n",
    "# Add fully connected layers\n",
    "dense1 = Dense(64, activation='relu')(concatenated)\n",
    "dropout1 = Dropout(0.2)(dense1)\n",
    "dense2 = Dense(32, activation='relu')(dropout1)\n",
    "dropout2 = Dropout(0.2)(dense2)\n",
    "output = Dense(1)(dropout2)\n",
    "\n",
    "# Add biases\n",
    "output = Add()([output, userBias, bookBias])\n",
    "\n",
    "# Construct the model\n",
    "model = Model(inputs=[userInput, bookInput], outputs=output)\n",
    "model.compile(optimizer='adam', loss='mean_squared_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "2695/2695 [==============================] - 46s 17ms/step - loss: 12.4392 - val_loss: 15.5754\n",
      "Epoch 2/10\n",
      "2695/2695 [==============================] - 43s 16ms/step - loss: 8.3046 - val_loss: 18.1543\n",
      "Epoch 3/10\n",
      "2695/2695 [==============================] - 44s 16ms/step - loss: 5.7069 - val_loss: 19.5512\n",
      "Epoch 4/10\n",
      "2695/2695 [==============================] - 44s 16ms/step - loss: 4.5643 - val_loss: 19.4920\n",
      "Epoch 5/10\n",
      "2695/2695 [==============================] - 51s 19ms/step - loss: 3.9836 - val_loss: 20.7656\n",
      "Epoch 6/10\n",
      "2695/2695 [==============================] - 47s 18ms/step - loss: 3.5594 - val_loss: 20.9753\n",
      "Epoch 7/10\n",
      "2695/2695 [==============================] - 47s 18ms/step - loss: 3.2386 - val_loss: 20.5059\n",
      "Epoch 8/10\n",
      "2695/2695 [==============================] - 48s 18ms/step - loss: 2.9561 - val_loss: 19.6403\n",
      "Epoch 9/10\n",
      "2695/2695 [==============================] - 47s 17ms/step - loss: 2.7265 - val_loss: 19.8864\n",
      "Epoch 10/10\n",
      "2695/2695 [==============================] - 44s 16ms/step - loss: 2.5339 - val_loss: 19.7307\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x1d8901e2610>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# %%\n",
    "# Preparing the dataset for training\n",
    "userIdEncoder = LabelEncoder()\n",
    "userIds = userIdEncoder.fit_transform(ratings['User-ID'].astype(str))\n",
    "\n",
    "bookIdEncoder = LabelEncoder()\n",
    "bookIds = bookIdEncoder.fit_transform(ratings['ISBN'].astype(str))\n",
    "ratings = ratings['Book-Rating'].values\n",
    "\n",
    "# Train the model\n",
    "model.fit([userIds, bookIds], ratings, epochs=10, validation_split=0.2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
