{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\josem\\AppData\\Local\\Temp\\ipykernel_2892\\1208284301.py:4: DtypeWarning: Columns (3) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  books_df = pd.read_csv('Books.csv')\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Cargar los datos\n",
    "books_df = pd.read_csv('Books.csv')\n",
    "ratings_df = pd.read_csv('Ratings.csv')\n",
    "users_df = pd.read_csv('Users.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         ISBN                                         Book-Title  \\\n",
      "0  0195153448                                Classical Mythology   \n",
      "1  0002005018                                       Clara Callan   \n",
      "2  0060973129                               Decision in Normandy   \n",
      "3  0374157065  Flu: The Story of the Great Influenza Pandemic...   \n",
      "4  0393045218                             The Mummies of Urumchi   \n",
      "\n",
      "            Book-Author Year-Of-Publication                   Publisher  \\\n",
      "0    Mark P. O. Morford                2002     Oxford University Press   \n",
      "1  Richard Bruce Wright                2001       HarperFlamingo Canada   \n",
      "2          Carlo D'Este                1991             HarperPerennial   \n",
      "3      Gina Bari Kolata                1999        Farrar Straus Giroux   \n",
      "4       E. J. W. Barber                1999  W. W. Norton &amp; Company   \n",
      "\n",
      "                                         Image-URL-S  \\\n",
      "0  http://images.amazon.com/images/P/0195153448.0...   \n",
      "1  http://images.amazon.com/images/P/0002005018.0...   \n",
      "2  http://images.amazon.com/images/P/0060973129.0...   \n",
      "3  http://images.amazon.com/images/P/0374157065.0...   \n",
      "4  http://images.amazon.com/images/P/0393045218.0...   \n",
      "\n",
      "                                         Image-URL-M  \\\n",
      "0  http://images.amazon.com/images/P/0195153448.0...   \n",
      "1  http://images.amazon.com/images/P/0002005018.0...   \n",
      "2  http://images.amazon.com/images/P/0060973129.0...   \n",
      "3  http://images.amazon.com/images/P/0374157065.0...   \n",
      "4  http://images.amazon.com/images/P/0393045218.0...   \n",
      "\n",
      "                                         Image-URL-L  \n",
      "0  http://images.amazon.com/images/P/0195153448.0...  \n",
      "1  http://images.amazon.com/images/P/0002005018.0...  \n",
      "2  http://images.amazon.com/images/P/0060973129.0...  \n",
      "3  http://images.amazon.com/images/P/0374157065.0...  \n",
      "4  http://images.amazon.com/images/P/0393045218.0...  \n",
      "   User-ID        ISBN  Book-Rating\n",
      "0   276725  034545104X            0\n",
      "1   276726  0155061224            5\n",
      "2   276727  0446520802            0\n",
      "3   276729  052165615X            3\n",
      "4   276729  0521795028            6\n",
      "   User-ID                            Location   Age\n",
      "0        1                  nyc, new york, usa   NaN\n",
      "1        2           stockton, california, usa  18.0\n",
      "2        3     moscow, yukon territory, russia   NaN\n",
      "3        4           porto, v.n.gaia, portugal  17.0\n",
      "4        5  farnborough, hants, united kingdom   NaN\n"
     ]
    }
   ],
   "source": [
    "# EDA básico\n",
    "print(books_df.head())\n",
    "print(ratings_df.head())\n",
    "print(users_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              ISBN      Book-Title      Book-Author  Year-Of-Publication  \\\n",
      "count       271360          271360           271358               271360   \n",
      "unique      271360          242135           102022                  202   \n",
      "top     0195153448  Selected Poems  Agatha Christie                 2002   \n",
      "freq             1              27              632                13903   \n",
      "\n",
      "        Publisher                                        Image-URL-S  \\\n",
      "count      271358                                             271360   \n",
      "unique      16807                                             271044   \n",
      "top     Harlequin  http://images.amazon.com/images/P/185326119X.0...   \n",
      "freq         7535                                                  2   \n",
      "\n",
      "                                              Image-URL-M  \\\n",
      "count                                              271360   \n",
      "unique                                             271044   \n",
      "top     http://images.amazon.com/images/P/185326119X.0...   \n",
      "freq                                                    2   \n",
      "\n",
      "                                              Image-URL-L  \n",
      "count                                              271357  \n",
      "unique                                             271041  \n",
      "top     http://images.amazon.com/images/P/225307649X.0...  \n",
      "freq                                                    2  \n",
      "            User-ID   Book-Rating\n",
      "count  1.149780e+06  1.149780e+06\n",
      "mean   1.403864e+05  2.866950e+00\n",
      "std    8.056228e+04  3.854184e+00\n",
      "min    2.000000e+00  0.000000e+00\n",
      "25%    7.034500e+04  0.000000e+00\n",
      "50%    1.410100e+05  0.000000e+00\n",
      "75%    2.110280e+05  7.000000e+00\n",
      "max    2.788540e+05  1.000000e+01\n",
      "            User-ID            Age\n",
      "count  278858.00000  168096.000000\n",
      "mean   139429.50000      34.751434\n",
      "std     80499.51502      14.428097\n",
      "min         1.00000       0.000000\n",
      "25%     69715.25000      24.000000\n",
      "50%    139429.50000      32.000000\n",
      "75%    209143.75000      44.000000\n",
      "max    278858.00000     244.000000\n"
     ]
    }
   ],
   "source": [
    "print(books_df.describe())\n",
    "print(ratings_df.describe())\n",
    "print(users_df.describe())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ISBN                   0\n",
      "Book-Title             0\n",
      "Book-Author            2\n",
      "Year-Of-Publication    0\n",
      "Publisher              2\n",
      "Image-URL-S            0\n",
      "Image-URL-M            0\n",
      "Image-URL-L            3\n",
      "dtype: int64\n",
      "User-ID        0\n",
      "ISBN           0\n",
      "Book-Rating    0\n",
      "dtype: int64\n",
      "User-ID          0\n",
      "Location         0\n",
      "Age         110762\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Verificar valores nulos\n",
    "print(books_df.isnull().sum())\n",
    "print(ratings_df.isnull().sum())\n",
    "print(users_df.isnull().sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Limpieza básica\n",
    "# Convertir ISBN a string\n",
    "books_df['ISBN'] = books_df['ISBN'].astype(str)\n",
    "ratings_df['ISBN'] = ratings_df['ISBN'].astype(str)\n",
    "\n",
    "# Convertir User-ID a int\n",
    "users_df['User-ID'] = users_df['User-ID'].astype(int)\n",
    "ratings_df['User-ID'] = ratings_df['User-ID'].astype(int)\n",
    "\n",
    "# Tratamiento de valores nulos en 'Age' por ejemplo\n",
    "users_df['Age'].fillna(users_df['Age'].mean(), inplace=True)\n",
    "\n",
    "# Puedes necesitar más preprocesamiento dependiendo de los requerimientos de tus modelos\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 549. GiB for an array with shape (271360, 271360) and data type float64",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\josem\\OneDrive\\Escritorio\\archive\\main.ipynb Cell 6\u001b[0m line \u001b[0;36m1\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/josem/OneDrive/Escritorio/archive/main.ipynb#W3sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m \u001b[39m# Calcular la matriz de similitud de coseno\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/josem/OneDrive/Escritorio/archive/main.ipynb#W3sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msklearn\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmetrics\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpairwise\u001b[39;00m \u001b[39mimport\u001b[39;00m linear_kernel\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/josem/OneDrive/Escritorio/archive/main.ipynb#W3sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m cosine_sim \u001b[39m=\u001b[39m linear_kernel(tfidf_matrix, tfidf_matrix)\n",
      "File \u001b[1;32mc:\\Users\\josem\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py:211\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    205\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m    206\u001b[0m     \u001b[39mwith\u001b[39;00m config_context(\n\u001b[0;32m    207\u001b[0m         skip_parameter_validation\u001b[39m=\u001b[39m(\n\u001b[0;32m    208\u001b[0m             prefer_skip_nested_validation \u001b[39mor\u001b[39;00m global_skip_validation\n\u001b[0;32m    209\u001b[0m         )\n\u001b[0;32m    210\u001b[0m     ):\n\u001b[1;32m--> 211\u001b[0m         \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m    212\u001b[0m \u001b[39mexcept\u001b[39;00m InvalidParameterError \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    213\u001b[0m     \u001b[39m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[0;32m    214\u001b[0m     \u001b[39m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[0;32m    215\u001b[0m     \u001b[39m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[0;32m    216\u001b[0m     \u001b[39m# message to avoid confusion.\u001b[39;00m\n\u001b[0;32m    217\u001b[0m     msg \u001b[39m=\u001b[39m re\u001b[39m.\u001b[39msub(\n\u001b[0;32m    218\u001b[0m         \u001b[39mr\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mparameter of \u001b[39m\u001b[39m\\\u001b[39m\u001b[39mw+ must be\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m    219\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mparameter of \u001b[39m\u001b[39m{\u001b[39;00mfunc\u001b[39m.\u001b[39m\u001b[39m__qualname__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m must be\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m    220\u001b[0m         \u001b[39mstr\u001b[39m(e),\n\u001b[0;32m    221\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\josem\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\pairwise.py:1329\u001b[0m, in \u001b[0;36mlinear_kernel\u001b[1;34m(X, Y, dense_output)\u001b[0m\n\u001b[0;32m   1304\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m   1305\u001b[0m \u001b[39mCompute the linear kernel between X and Y.\u001b[39;00m\n\u001b[0;32m   1306\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1326\u001b[0m \u001b[39m    The Gram matrix of the linear kernel, i.e. `X @ Y.T`.\u001b[39;00m\n\u001b[0;32m   1327\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m   1328\u001b[0m X, Y \u001b[39m=\u001b[39m check_pairwise_arrays(X, Y)\n\u001b[1;32m-> 1329\u001b[0m \u001b[39mreturn\u001b[39;00m safe_sparse_dot(X, Y\u001b[39m.\u001b[39;49mT, dense_output\u001b[39m=\u001b[39;49mdense_output)\n",
      "File \u001b[1;32mc:\\Users\\josem\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\extmath.py:201\u001b[0m, in \u001b[0;36msafe_sparse_dot\u001b[1;34m(a, b, dense_output)\u001b[0m\n\u001b[0;32m    193\u001b[0m     ret \u001b[39m=\u001b[39m a \u001b[39m@\u001b[39m b\n\u001b[0;32m    195\u001b[0m \u001b[39mif\u001b[39;00m (\n\u001b[0;32m    196\u001b[0m     sparse\u001b[39m.\u001b[39missparse(a)\n\u001b[0;32m    197\u001b[0m     \u001b[39mand\u001b[39;00m sparse\u001b[39m.\u001b[39missparse(b)\n\u001b[0;32m    198\u001b[0m     \u001b[39mand\u001b[39;00m dense_output\n\u001b[0;32m    199\u001b[0m     \u001b[39mand\u001b[39;00m \u001b[39mhasattr\u001b[39m(ret, \u001b[39m\"\u001b[39m\u001b[39mtoarray\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    200\u001b[0m ):\n\u001b[1;32m--> 201\u001b[0m     \u001b[39mreturn\u001b[39;00m ret\u001b[39m.\u001b[39;49mtoarray()\n\u001b[0;32m    202\u001b[0m \u001b[39mreturn\u001b[39;00m ret\n",
      "File \u001b[1;32mc:\\Users\\josem\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\scipy\\sparse\\_compressed.py:1050\u001b[0m, in \u001b[0;36m_cs_matrix.toarray\u001b[1;34m(self, order, out)\u001b[0m\n\u001b[0;32m   1048\u001b[0m \u001b[39mif\u001b[39;00m out \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m order \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m   1049\u001b[0m     order \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_swap(\u001b[39m'\u001b[39m\u001b[39mcf\u001b[39m\u001b[39m'\u001b[39m)[\u001b[39m0\u001b[39m]\n\u001b[1;32m-> 1050\u001b[0m out \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_process_toarray_args(order, out)\n\u001b[0;32m   1051\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (out\u001b[39m.\u001b[39mflags\u001b[39m.\u001b[39mc_contiguous \u001b[39mor\u001b[39;00m out\u001b[39m.\u001b[39mflags\u001b[39m.\u001b[39mf_contiguous):\n\u001b[0;32m   1052\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m'\u001b[39m\u001b[39mOutput array must be C or F contiguous\u001b[39m\u001b[39m'\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\josem\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\scipy\\sparse\\_base.py:1267\u001b[0m, in \u001b[0;36m_spbase._process_toarray_args\u001b[1;34m(self, order, out)\u001b[0m\n\u001b[0;32m   1265\u001b[0m     \u001b[39mreturn\u001b[39;00m out\n\u001b[0;32m   1266\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m-> 1267\u001b[0m     \u001b[39mreturn\u001b[39;00m np\u001b[39m.\u001b[39;49mzeros(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mshape, dtype\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdtype, order\u001b[39m=\u001b[39;49morder)\n",
      "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate 549. GiB for an array with shape (271360, 271360) and data type float64"
     ]
    }
   ],
   "source": [
    "# Pseudocódigo - Necesitarías generar un perfil de usuario basado en las características de los libros que ha calificado.\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Por ejemplo, usar el título del libro para la recomendación\n",
    "tfidf = TfidfVectorizer(stop_words='english')\n",
    "books_df['Book-Title'] = books_df['Book-Title'].fillna('')\n",
    "tfidf_matrix = tfidf.fit_transform(books_df['Book-Title'])\n",
    "\n",
    "# Calcular la matriz de similitud de coseno\n",
    "from sklearn.metrics.pairwise import linear_kernel\n",
    "cosine_sim = linear_kernel(tfidf_matrix, tfidf_matrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pseudocódigo para la construcción de la red neuronal\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Embedding, Flatten, Dot, Dense\n",
    "\n",
    "# Definición de las entradas\n",
    "book_input = Input(shape=[1], name=\"Book-Input\")\n",
    "book_embedding = Embedding(n_books + 1, 5, name=\"Book-Embedding\")(book_input)\n",
    "book_vec = Flatten(name=\"Flatten-Books\")(book_embedding)\n",
    "\n",
    "user_input = Input(shape=[1], name=\"User-Input\")\n",
    "user_embedding = Embedding(n_users + 1, 5, name=\"User-Embedding\")(user_input)\n",
    "user_vec = Flatten(name=\"Flatten-Users\")(user_embedding)\n",
    "\n",
    "# Producto punto de los vectores\n",
    "prod = Dot(name=\"Dot-Product\", axes=1)([book_vec, user_vec])\n",
    "\n",
    "# Capas fully connected\n",
    "fc1 = Dense(128, activation='relu')(prod)\n",
    "fc2 = Dense(32, activation='relu')(fc1)\n",
    "output = Dense(1)(fc2)\n",
    "\n",
    "model = Model([user_input, book_input], output)\n",
    "model.compile('adam', 'mean_squared_error')\n",
    "\n",
    "# Suponiendo que tienes los inputs preparados como 'user_data' y 'book_data' y las etiquetas como 'ratings'\n",
    "history = model.fit([user_data, book_data], ratings, epochs=10, verbose=1)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
