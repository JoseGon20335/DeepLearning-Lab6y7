{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of dataframe:  (103113, 8)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>User-ID</th>\n",
       "      <th>Book-Rating</th>\n",
       "      <th>Book-Title</th>\n",
       "      <th>Book-Author</th>\n",
       "      <th>Year-Of-Publication</th>\n",
       "      <th>Publisher</th>\n",
       "      <th>Location</th>\n",
       "      <th>Age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>887470</th>\n",
       "      <td>4556</td>\n",
       "      <td>8</td>\n",
       "      <td>Abduction</td>\n",
       "      <td>Robin Cook</td>\n",
       "      <td>2000</td>\n",
       "      <td>Berkley Publishing Group</td>\n",
       "      <td>south berwick, maine, usa</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56511</th>\n",
       "      <td>234623</td>\n",
       "      <td>0</td>\n",
       "      <td>Nancy Kerrigan: In My Own Words</td>\n",
       "      <td>Nancy Kerrigan</td>\n",
       "      <td>1996</td>\n",
       "      <td>Disney Pr (Jp)</td>\n",
       "      <td>scarborough, maine, usa</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>238538</th>\n",
       "      <td>190925</td>\n",
       "      <td>0</td>\n",
       "      <td>Bad Girl : A Novel</td>\n",
       "      <td>MICHELE JAFFE</td>\n",
       "      <td>2003</td>\n",
       "      <td>Ballantine Books</td>\n",
       "      <td>hobe sound, florida, usa</td>\n",
       "      <td>51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>610781</th>\n",
       "      <td>56661</td>\n",
       "      <td>0</td>\n",
       "      <td>The Joy Luck Club</td>\n",
       "      <td>Amy Tan</td>\n",
       "      <td>1994</td>\n",
       "      <td>Prentice Hall (K-12)</td>\n",
       "      <td>green, ohio, usa</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179676</th>\n",
       "      <td>56856</td>\n",
       "      <td>0</td>\n",
       "      <td>The Pleasure of My Company: A Novel</td>\n",
       "      <td>Steve Martin</td>\n",
       "      <td>2003</td>\n",
       "      <td>Hyperion</td>\n",
       "      <td>escondido, california, usa</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        User-ID  Book-Rating                           Book-Title  \\\n",
       "887470     4556            8                            Abduction   \n",
       "56511    234623            0      Nancy Kerrigan: In My Own Words   \n",
       "238538   190925            0                   Bad Girl : A Novel   \n",
       "610781    56661            0                    The Joy Luck Club   \n",
       "179676    56856            0  The Pleasure of My Company: A Novel   \n",
       "\n",
       "           Book-Author  Year-Of-Publication                 Publisher  \\\n",
       "887470      Robin Cook                 2000  Berkley Publishing Group   \n",
       "56511   Nancy Kerrigan                 1996            Disney Pr (Jp)   \n",
       "238538   MICHELE JAFFE                 2003          Ballantine Books   \n",
       "610781         Amy Tan                 1994      Prentice Hall (K-12)   \n",
       "179676    Steve Martin                 2003                  Hyperion   \n",
       "\n",
       "                          Location  Age  \n",
       "887470   south berwick, maine, usa   34  \n",
       "56511      scarborough, maine, usa   34  \n",
       "238538    hobe sound, florida, usa   51  \n",
       "610781            green, ohio, usa   34  \n",
       "179676  escondido, california, usa   23  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Input, Flatten, Embedding, Concatenate\n",
    "from tensorflow.keras.models import Model\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "dataframe = pd.read_csv('data/processed.csv')\n",
    "\n",
    "dataframe = dataframe.sample(frac=0.1, random_state=1)\n",
    "\n",
    "print(\"Shape of dataframe: \", dataframe.shape)\n",
    "dataframe.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(stop_words='english')\n",
    "X = vectorizer.fit_transform(dataframe['Book-Title'])\n",
    "X_train, X_test = train_test_split(X, test_size=0.2, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "userInput = Input(shape=(1,))\n",
    "userEmbedding = Embedding(input_dim=263407, output_dim=32)(userInput)\n",
    "userVector = Flatten()(userEmbedding)\n",
    "userOutput = Dense(1)(userVector)\n",
    "\n",
    "bookInput = Input(shape=(1,))\n",
    "bookEmbedding = Embedding(input_dim=270713, output_dim=32)(bookInput)\n",
    "bookVector = Flatten()(bookEmbedding)\n",
    "bookOutput = Dense(1)(bookVector)\n",
    "\n",
    "concatenate = Concatenate()([userVector, bookVector])\n",
    "\n",
    "dense = Dense(128, activation='relu')(concatenate)\n",
    "output = Dense(1)(dense)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Keras is training/fitting/evaluating on array-like data. Keras may not be optimized for this format, so if your input data format is supported by TensorFlow I/O (https://github.com/tensorflow/io) we recommend using that to load a Dataset instead.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Data cardinality is ambiguous:\n  x sizes: 103113, 82490\n  y sizes: 103113\nMake sure all arrays contain the same number of samples.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/Users/ls/Documents/Projects/DeepLearning-Lab6y7/filterBased.ipynb Cell 4\u001b[0m line \u001b[0;36m6\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/ls/Documents/Projects/DeepLearning-Lab6y7/filterBased.ipynb#W3sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m model\u001b[39m.\u001b[39mcompile(loss\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mmean_squared_error\u001b[39m\u001b[39m'\u001b[39m, optimizer\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39madam\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/ls/Documents/Projects/DeepLearning-Lab6y7/filterBased.ipynb#W3sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m early_stopping \u001b[39m=\u001b[39m EarlyStopping(monitor\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mval_loss\u001b[39m\u001b[39m'\u001b[39m, patience\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m, verbose\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/ls/Documents/Projects/DeepLearning-Lab6y7/filterBased.ipynb#W3sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m model\u001b[39m.\u001b[39;49mfit([dataframe[\u001b[39m'\u001b[39;49m\u001b[39mUser-ID\u001b[39;49m\u001b[39m'\u001b[39;49m], X_train], dataframe[\u001b[39m'\u001b[39;49m\u001b[39mBook-Rating\u001b[39;49m\u001b[39m'\u001b[39;49m], epochs\u001b[39m=\u001b[39;49m\u001b[39m10\u001b[39;49m, verbose\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m, callbacks\u001b[39m=\u001b[39;49m[early_stopping])\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[39m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[39m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[1;32m     71\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/keras/src/engine/data_adapter.py:1960\u001b[0m, in \u001b[0;36m_check_data_cardinality\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m   1953\u001b[0m     msg \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m  \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m sizes: \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[1;32m   1954\u001b[0m         label,\n\u001b[1;32m   1955\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m, \u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mjoin(\n\u001b[1;32m   1956\u001b[0m             \u001b[39mstr\u001b[39m(i\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m]) \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m tf\u001b[39m.\u001b[39mnest\u001b[39m.\u001b[39mflatten(single_data)\n\u001b[1;32m   1957\u001b[0m         ),\n\u001b[1;32m   1958\u001b[0m     )\n\u001b[1;32m   1959\u001b[0m msg \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mMake sure all arrays contain the same number of samples.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m-> 1960\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(msg)\n",
      "\u001b[0;31mValueError\u001b[0m: Data cardinality is ambiguous:\n  x sizes: 103113, 82490\n  y sizes: 103113\nMake sure all arrays contain the same number of samples."
     ]
    }
   ],
   "source": [
    "model = Model([userInput, bookInput], output)\n",
    "model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=2, verbose=1)\n",
    "\n",
    "model.fit([dataframe['User-ID'], X_train], dataframe['Book-Rating'], epochs=10, verbose=1, callbacks=[early_stopping])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
